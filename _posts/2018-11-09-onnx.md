---
layout: post
title: "ONNX, AI 모델 오픈소스 포맷"
tags: [onnx, onnxmltools, hdf5, keras, 딥러닝, 모델변환]
comments: true
---

수 많은 딥러닝 프레임워크에서 각각의 포맷으로 모델을 생성합니다. PyTorch를 통해서 생성한 모델을 텐서플로우에서 사용 하려면 어떻게 해야 할까요? 이러한 문제를 해결하기 위해서 ONNX가 등장합니다. 각각의 딥러닝 프레임워크에서 생성한 모델을 ONNX 포맷으로 변경 후, 원하는 프레임워크에 맞게 다시 변경 할 수 있습니다.

여기서는 케라스를 통해서 .h5 (HDF5 포맷) 모델을 생성하고, 생성된 .h5 모델을 어떻게 ONNX 포맷으로 변경 할 수 있는지 알아 보도록 하겠습니다. 오픈소스인 onnxmltools을 사용해서 변환하겠습니다.

## [ONNX](https://github.com/onnx/onnx)
- Open Neural Network Exchange
- AI 모델의 오픈소스 포맷 제공
- 다른 오픈소스 framework 간의 상호 호환을 지원
- 케라스, 텐서플로우, Caffe2, PyTorch, CNTK 등의 딥러닝 프레임워크를 통해서 생성한 모델을 ONNX 표준 모델 포맷으로 변환하고 역으로  ONNX에서 다른 형태의 모델 포맷으로 변환 가능
  ![ONNX Supported Tools](/images/2018/11/09_onnx/supported_tools.png)

## [ONNXMLTools](https://github.com/onnx/onnxmltools)
- 생성한 모델을  ONNX 포맷으로 변경하는 툴
- 현재 지원하는 툴킷은 아래와 같음
  - Apple Core ML
  - scikit-leran
  - Keras (version 2.0.0 or higher)
  - LightGBM
- 패키지 설치
  ```bash
  pip install onnxmltools
  ```

## ONNXMLTools를 통한 h5 -> onnx 변환 소스코드

load_model() 함수를 통해서 .h5 모델을 로드합니다. onnxmltools을 통해서 .h5 모델을 onnx 모델로 변경하고, 이를 json 형식 or protobuf 형식으로 저장 할 수 있습니다.

```python
import os
import argparse
import onnxmltools

from keras.models import load_model

parser = argparse.ArgumentParser()
parser.add_argument('-mf', '--model_filename', required=True)
args = parser.parse_args()

assert(os.path.exists(args.model_filename))

# load model
model = load_model(args.model_filename)

# convert keras model to onnx model
onnx_model = onnxmltools.convert_keras(model)

# save as text
onnxmltools.utils.save_text(onnx_model, args.model_filename + ".json")

# save as protobuf
onnxmltools.utils.save_model(onnx_model, args.model_filename + ".onnx")
```

## onnx 모델의 json 포맷 파일 예시

위 예제에서 로드한 모델을 mnist를 분류하는 단순한 MLP 모델이였습니다. onnxmltools을 통해서 .h5 -> .json, onnx로 변환하고 아래의 내용은 변환된 .json의 실제 내용입니다. 노드, input, activation, weights 등 모델을 설명하는 모든 내용이 포함됨을 알 수 있습니다.

```json
ir_version: 3
producer_name: "OnnxMLTools"
producer_version: "1.2.2.0129"
domain: "onnxml"
model_version: 0
doc_string: ""
graph {
  node {
    input: "dense_1_input_0"
    input: "W"
    output: "transformed_tensor"
    name: "_class__keras_layers_core_Dense__"
    op_type: "MatMul"
    domain: ""
  }
  node {
    input: "transformed_tensor"
    input: "B"
    output: "biased_tensor_name"
    name: "Add"
    op_type: "Add"
    domain: ""
  }
  node {
    input: "biased_tensor_name"
    output: "dense_1_Relu_0"
    name: "Relu"
    op_type: "Relu"
    domain: ""
  }
  node {
    input: "dense_1_Relu_0"
    input: "W1"
    output: "transformed_tensor1"
    name: "_class__keras_layers_core_Dense__1"
    op_type: "MatMul"
    domain: ""
  }
  node {
    input: "transformed_tensor1"
    input: "B1"
    output: "biased_tensor_name1"
    name: "Add1"
    op_type: "Add"
    domain: ""
  }
  node {
    input: "biased_tensor_name1"
    output: "dense_2_Relu_0"
    name: "Relu1"
    op_type: "Relu"
    domain: ""
  }
  node {
    input: "dense_2_Relu_0"
    input: "W2"
    output: "transformed_tensor2"
    name: "_class__keras_layers_core_Dense__2"
    op_type: "MatMul"
    domain: ""
  }
  node {
    input: "transformed_tensor2"
    input: "B2"
    output: "biased_tensor_name2"
    name: "Add2"
    op_type: "Add"
    domain: ""
  }
  node {
    input: "biased_tensor_name2"
    output: "dense_3_BiasAdd_01"
    name: "Identity"
    op_type: "Identity"
    domain: ""
  }
  name: "5b968e7230eb4ddfbb070465794b5a27"
  initializer {
    dims: 1
    dims: 64
    data_type: FLOAT
    float_data: -0.14707930386066437
    float_data: -0.09477967023849487
    float_data: -0.026459425687789917
    float_data: -0.04473927617073059
    float_data: -0.1713748723268509
    float_data: -0.04929053783416748
    float_data: 0.12901613116264343
    float_data: 0.1409318745136261
    float_data: -0.125150665640831
    float_data: -0.08415964245796204
    float_data: -0.09024816751480103
    ...
      
```

